{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanugra/computer-vision-with-python/blob/master/segmentasi_ped.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRpDqlHcoQnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4579c6-137d-478c-f9ed-8f73ad9ba27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vEtL5aOolR2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTSI9DOWqDaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a90fecc-d0fe-4a2b-e235-c913f9e82782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Folder '/content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/hasil/20240824_08:53/' created.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import precision_recall_curve, auc, recall_score\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import os\n",
        "#tf.config.optimizer.set_jit(False)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#link_data = '/content/drive/MyDrive/S3/segmentasi ped/v2/'\n",
        "#link_model = '/content/drive/MyDrive/S3/segmentasi ped/v3_filter/model_20240820 02:57.keras'\n",
        "\n",
        "link_data = '/content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/'\n",
        "folder_path = link_data + 'hasil/' + datetime.datetime.now().strftime(\"%Y%m%d_%H:%M\") + '/'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path )\n",
        "    print(f\"Folder '{folder_path}' created.\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_path}' already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekxpuvt9qj5n"
      },
      "outputs": [],
      "source": [
        "def load_dt(link):\n",
        "    dt_load = np.load(link , allow_pickle=True)\n",
        "    dt_ = dt_load['data']\n",
        "    dt_ = dt_.tolist()\n",
        "    return np.array(dt_)\n",
        "\n",
        "def iou_metric(y_true, y_pred):\n",
        "    intersection = np.sum((y_true * y_pred), axis=(1, 2, 3))\n",
        "    union = np.sum(y_true, axis=(1, 2, 3)) + np.sum(y_pred, axis=(1, 2, 3)) - intersection\n",
        "    iou = np.mean((intersection + 1e-7) / (union + 1e-7), axis=0)  # Adding a small epsilon to avoid division by zero\n",
        "    return iou\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    intersection = np.sum((y_true * y_pred), axis=(1, 2, 3))\n",
        "    dice = np.mean((2. * intersection + 1e-7) / (np.sum(y_true, axis=(1, 2, 3)) + np.sum(y_pred, axis=(1, 2, 3)) + 1e-7), axis=0)\n",
        "    return dice\n",
        "\n",
        "def calculate_ap(y_true, y_pred):\n",
        "    precision, recall, _ = precision_recall_curve(y_true.flatten(), y_pred.flatten())\n",
        "    ap = auc(recall, precision)\n",
        "    return ap\n",
        "\n",
        "def calculate_recall(y_true, y_pred):\n",
        "    return recall_score(y_true.flatten(), y_pred.flatten(), average='binary')\n",
        "\n",
        "\n",
        "def calculate_lra(y_true, y_pred, iou_threshold=0.5):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou >= iou_threshold\n",
        "\n",
        "def iou_metrics(y_true, y_pred):\n",
        "    # Cast y_true to float32 to match y_pred's type\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)  # Apply threshold to get binary predictions\n",
        "\n",
        "    # Calculate the intersection and union\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
        "    union = tf.reduce_sum(y_true, axis=(1, 2, 3)) + tf.reduce_sum(y_pred, axis=(1, 2, 3)) - intersection\n",
        "\n",
        "    # Compute IoU score\n",
        "    iou = tf.reduce_mean((intersection + 1e-7) / (union + 1e-7), axis=0)  # Adding epsilon to avoid division by zero\n",
        "    return iou\n",
        "\n",
        "def dice_coefficients(y_true, y_pred):\n",
        "    # Cast y_true to float32 to match y_pred's type\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)  # Apply threshold to get binary predictions\n",
        "\n",
        "    # Calculate the intersection\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
        "\n",
        "    # Calculate Dice coefficient\n",
        "    dice = tf.reduce_mean((2. * intersection + 1e-7) / (tf.reduce_sum(y_true, axis=(1, 2, 3)) + tf.reduce_sum(y_pred, axis=(1, 2, 3)) + 1e-7), axis=0)\n",
        "    return dice\n",
        "\n",
        "def evaluate_model(model_name, history,waktu):\n",
        "    # Train the model with the learning rate scheduler\n",
        "\n",
        "    # Print history keys\n",
        "    print(f\"History keys for {model_name}: {history.history.keys()}\")\n",
        "\n",
        "    # Plotting training and validation loss and accuracy\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'{model_name} - Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'{model_name} - Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(folder_path + 'acc_performa.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Plotting iou and dice score\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['iou_metrics'], label='Training IoU')\n",
        "    plt.plot(history.history['val_iou_metrics'], label='Validation IoU')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.title(f'{model_name} - IoU')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['dice_coefficients'], label='Training Dice')\n",
        "    plt.plot(history.history['val_dice_coefficients'], label='Validation Dice')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Dice')\n",
        "    plt.title(f'{model_name} - Dice')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(folder_path + 'iou_performa.png', dpi=300)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYFjbKfYql4_"
      },
      "outputs": [],
      "source": [
        "def unet_model(input_size=(256, 256, 9)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
        "    up4 = layers.concatenate([up4, conv2])\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(up4)\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up5 = layers.UpSampling2D(size=(2, 2))(conv4)\n",
        "    up5 = layers.concatenate([up5, conv1])\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(up5)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(2, 1, activation='sigmoid')(conv5)  # 2 output channels for left and right segmentation\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwEhjAgjqpEq",
        "outputId": "e340a5c0-49b7-487c-eaa3-e68a004d088a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input loaded 1\n",
            "target loaded 1\n",
            "input loaded 2\n",
            "target loaded 2\n",
            "input loaded 3\n",
            "target loaded 3\n",
            "input loaded 4\n",
            "target loaded 4\n",
            "input loaded 5\n",
            "target loaded 5\n",
            "input loaded 6\n",
            "target loaded 6\n",
            "input loaded 7\n",
            "target loaded 7\n",
            "input loaded 8\n",
            "target loaded 8\n",
            "input loaded 9\n",
            "target loaded 9\n",
            "input loaded 10\n",
            "target loaded 10\n",
            "input loaded 11\n",
            "target loaded 11\n",
            "input loaded 12\n",
            "target loaded 12\n",
            "input loaded 13\n",
            "target loaded 13\n",
            "input loaded 14\n",
            "target loaded 14\n",
            "input loaded 15\n",
            "target loaded 15\n",
            "input loaded 16\n",
            "target loaded 16\n",
            "input loaded 17\n",
            "target loaded 17\n",
            "input loaded 18\n",
            "target loaded 18\n",
            "input loaded 19\n",
            "target loaded 19\n",
            "input loaded 20\n",
            "target loaded 20\n",
            "input loaded 21\n",
            "target loaded 21\n",
            "input loaded 22\n",
            "target loaded 22\n",
            "input loaded 23\n",
            "target loaded 23\n",
            "input loaded 24\n",
            "target loaded 24\n",
            "input loaded 25\n",
            "target loaded 25\n",
            "input loaded 26\n",
            "target loaded 26\n",
            "input loaded 27\n",
            "target loaded 27\n",
            "input loaded 28\n",
            "target loaded 28\n",
            "input loaded 29\n",
            "target loaded 29\n",
            "input loaded 30\n",
            "target loaded 30\n",
            "input loaded 31\n",
            "target loaded 31\n",
            "input loaded 32\n",
            "target loaded 32\n",
            "input loaded 33\n",
            "target loaded 33\n",
            "data splitted\n",
            "(3733, 256, 256, 9) (800, 256, 256, 9) (3733, 256, 256, 2) (800, 256, 256, 2) (800, 256, 256, 9) (800, 256, 256, 2)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 9)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 64)         5248      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 128, 128, 256)        0         ['conv2d_5[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128, 128, 384)        0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 128, 128, 128)        442496    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 256, 256, 128)        0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 256, 256, 64)         110656    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 256, 256, 2)          130       ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1886658 (7.20 MB)\n",
            "Trainable params: 1886658 (7.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.3216 - iou_metrics: 0.5552 - dice_coefficients: 0.6557 \n",
            "Epoch 1: val_loss improved from inf to 0.03328, saving model to /content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/model_20240824_09:11.keras\n",
            "59/59 [==============================] - 1373s 23s/step - loss: 0.1149 - accuracy: 0.3216 - iou_metrics: 0.5552 - dice_coefficients: 0.6557 - val_loss: 0.0333 - val_accuracy: 0.9728 - val_iou_metrics: 0.8207 - val_dice_coefficients: 0.9006 - lr: 0.0010\n",
            "Epoch 2/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.4346 - iou_metrics: 0.8444 - dice_coefficients: 0.9143 \n",
            "Epoch 2: val_loss improved from 0.03328 to 0.02200, saving model to /content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/model_20240824_09:11.keras\n",
            "59/59 [==============================] - 1363s 23s/step - loss: 0.0304 - accuracy: 0.4346 - iou_metrics: 0.8444 - dice_coefficients: 0.9143 - val_loss: 0.0220 - val_accuracy: 0.1332 - val_iou_metrics: 0.8857 - val_dice_coefficients: 0.9385 - lr: 0.0010\n",
            "Epoch 3/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.1336 - iou_metrics: 0.9052 - dice_coefficients: 0.9497 \n",
            "Epoch 3: val_loss improved from 0.02200 to 0.01494, saving model to /content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/model_20240824_09:11.keras\n",
            "59/59 [==============================] - 1366s 23s/step - loss: 0.0172 - accuracy: 0.1336 - iou_metrics: 0.9052 - dice_coefficients: 0.9497 - val_loss: 0.0149 - val_accuracy: 0.1419 - val_iou_metrics: 0.9143 - val_dice_coefficients: 0.9548 - lr: 0.0010\n",
            "Epoch 4/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.1373 - iou_metrics: 0.9252 - dice_coefficients: 0.9608 \n",
            "Epoch 4: val_loss improved from 0.01494 to 0.01198, saving model to /content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/model_20240824_09:11.keras\n",
            "59/59 [==============================] - 1365s 23s/step - loss: 0.0126 - accuracy: 0.1373 - iou_metrics: 0.9252 - dice_coefficients: 0.9608 - val_loss: 0.0120 - val_accuracy: 0.1397 - val_iou_metrics: 0.9284 - val_dice_coefficients: 0.9627 - lr: 0.0010\n",
            "Epoch 5/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.1311 - iou_metrics: 0.9344 - dice_coefficients: 0.9659 \n",
            "Epoch 5: val_loss improved from 0.01198 to 0.01018, saving model to /content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/model_20240824_09:11.keras\n",
            "59/59 [==============================] - 1361s 23s/step - loss: 0.0108 - accuracy: 0.1311 - iou_metrics: 0.9344 - dice_coefficients: 0.9659 - val_loss: 0.0102 - val_accuracy: 0.1267 - val_iou_metrics: 0.9385 - val_dice_coefficients: 0.9681 - lr: 0.0010\n",
            "Epoch 6/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.1315 - iou_metrics: 0.9412 - dice_coefficients: 0.9695 \n",
            "Epoch 6: val_loss did not improve from 0.01018\n",
            "59/59 [==============================] - 1367s 23s/step - loss: 0.0095 - accuracy: 0.1315 - iou_metrics: 0.9412 - dice_coefficients: 0.9695 - val_loss: 0.0113 - val_accuracy: 0.1322 - val_iou_metrics: 0.9331 - val_dice_coefficients: 0.9652 - lr: 0.0010\n",
            "Epoch 7/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.1304 - iou_metrics: 0.9463 - dice_coefficients: 0.9723 \n",
            "Epoch 7: val_loss improved from 0.01018 to 0.00932, saving model to /content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/model_20240824_09:11.keras\n",
            "59/59 [==============================] - 1372s 23s/step - loss: 0.0087 - accuracy: 0.1304 - iou_metrics: 0.9463 - dice_coefficients: 0.9723 - val_loss: 0.0093 - val_accuracy: 0.1342 - val_iou_metrics: 0.9438 - val_dice_coefficients: 0.9710 - lr: 0.0010\n",
            "Epoch 8/8\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.1372 - iou_metrics: 0.9490 - dice_coefficients: 0.9737 \n",
            "Epoch 8: val_loss improved from 0.00932 to 0.00824, saving model to /content/drive/MyDrive/S3/segmentasi ped/v4_target hm binary/model_20240824_09:11.keras\n",
            "59/59 [==============================] - 1385s 23s/step - loss: 0.0082 - accuracy: 0.1372 - iou_metrics: 0.9490 - dice_coefficients: 0.9737 - val_loss: 0.0082 - val_accuracy: 0.1299 - val_iou_metrics: 0.9493 - val_dice_coefficients: 0.9739 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "#link_data = '/kaggle/input/ped-segmentasi/v2/'\n",
        "\n",
        "#id_vid = 2\n",
        "#input_image = load_dt(link_data + str(id_vid) + '_input.npz')\n",
        "#print('input loaded')\n",
        "#target_mask = load_dt(link_data + str(id_vid) + '_target.npz')\n",
        "#print('target loaded')\n",
        "\n",
        "#link_image = sorted(glob.glob(link_data + '*_input.npz'))\n",
        "#link_target = sorted(glob.glob(link_data + '*_target.npz'))\n",
        "\n",
        "input_image = []\n",
        "target_mask = []\n",
        "for id_f in range(1,34):\n",
        "  temp_input_image = load_dt(link_data + str(id_f) + '_input.npz')\n",
        "  print('input loaded', id_f)\n",
        "  temp_target_mask = load_dt(link_data + str(id_f) + '_target.npz')\n",
        "  print('target loaded', id_f)\n",
        "  input_image.extend(temp_input_image)\n",
        "  target_mask.extend(temp_target_mask)\n",
        "#  if len(input_image) < 3000:\n",
        "#    input_image.extend(temp_input_image)\n",
        "#    target_mask.extend(temp_target_mask)\n",
        "#  else:\n",
        "#    break\n",
        "\n",
        "input_image = np.array(input_image)\n",
        "target_mask = np.array(target_mask)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(input_image, target_mask, test_size=0.2, random_state=42)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(input_image, target_mask, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print('data splitted')\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_val.shape, y_val.shape)\n",
        "waktu = datetime.datetime.now().strftime(\"%Y%m%d_%H:%M\")\n",
        "\n",
        "# Instantiate and compile the model\n",
        "model = unet_model()\n",
        "#model.load_weights(link_data + 'model_20240822 07:55.keras')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', iou_metrics, dice_coefficients])\n",
        "model.summary()\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "model_checkpoint = ModelCheckpoint(link_data + 'model_'+str(waktu) + '.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=8,\n",
        "                    #initial_epoch=5,\n",
        "                    validation_data= (X_val, y_val),\n",
        "                    batch_size=64,\n",
        "                    callbacks=[lr_scheduler,early_stopping,model_checkpoint]\n",
        "        )\n",
        "model.save(folder_path+'model_unet.h5')\n",
        "model.save_weights(folder_path+'weight_unet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J_QqzM6UugB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cdd4fd-d017-4cfd-f4a1-2d073a897c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 43s 2s/step\n",
            "IoU Score: 0.9499472930850135\n",
            "Dice Coefficient: 0.9742287301469023\n",
            "Average Precision (AP): 0.9759489072444717\n",
            "Recall: 0.9844867415913383\n",
            "Localization Recall Accuracy (LRA) : True\n",
            "FPS: 17.17\n"
          ]
        }
      ],
      "source": [
        "\n",
        "evaluate_model(\"Unet Segmentation\", history, waktu)\n",
        "\n",
        "#y_pred = model.predict(X_test)\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "# Perform the prediction\n",
        "y_pred = model.predict(X_test)\n",
        "end_time = time.time()\n",
        "# Calculate time taken per frame\n",
        "time_per_frame = end_time - start_time\n",
        "num_frames = X_test.shape[0]\n",
        "time_per_frame = time_per_frame / num_frames\n",
        "fps = 1 / time_per_frame\n",
        "\n",
        "y_pred_thresholded = (y_pred > 0.5).astype(np.float32)\n",
        "\n",
        "iou_score = iou_metric(y_test, y_pred_thresholded)\n",
        "dice_score = dice_coefficient(y_test, y_pred_thresholded)\n",
        "ap = calculate_ap(y_test, y_pred_thresholded)\n",
        "recall = calculate_recall(y_test, y_pred_thresholded)\n",
        "lra = calculate_lra(y_test, y_pred_thresholded)\n",
        "\n",
        "print(f'IoU Score: {iou_score}')\n",
        "print(f'Dice Coefficient: {dice_score}')\n",
        "print(f'Average Precision (AP): {ap}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'Localization Recall Accuracy (LRA) : {lra}')\n",
        "print(f\"FPS: {fps:.2f}\")\n",
        "\n",
        "np.savez_compressed(folder_path +'y_pred.npz', data=y_pred)\n",
        "np.savez_compressed(folder_path +'y_test.npz', data=y_test)\n",
        "np.savez_compressed(folder_path +'X_test.npz', data=X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LteEANtwrC5O"
      },
      "outputs": [],
      "source": [
        "model.save(folder_path+'model_unet.keras')\n",
        "def check_pred():\n",
        "  y_pred = load_dt(link_data + 'hasil/20240823 04:25y_pred_unet.npz')\n",
        "  y_test = load_dt(link_data + 'hasil/20240823 04:25_y_test_unet.npz')\n",
        "  X_test = load_dt(link_data + '17_input.npz')\n",
        "  y_pred_thresholded = (y_pred > 0.5).astype(np.float32)\n",
        "\n",
        "\n",
        "  iou_score = iou_metric(y_test, y_pred_thresholded)\n",
        "  dice_score = dice_coefficient(y_test, y_pred_thresholded)\n",
        "  ap = calculate_ap(y_test, y_pred_thresholded)\n",
        "  recall = calculate_recall(y_test, y_pred_thresholded)\n",
        "  lra = calculate_lra(y_test, y_pred_thresholded)\n",
        "\n",
        "  model = unet_model()\n",
        "  model.summary()\n",
        "\n",
        "  model = tf.keras.models.load_model(link_data + 'hasil/model_20240823 04:25.keras', custom_objects={\n",
        "      'dice_coefficients': dice_coefficients,\n",
        "      'iou_metrics': iou_metrics\n",
        "  })\n",
        "\n",
        "\n",
        "  start_time = time.time()\n",
        "  # Perform the prediction\n",
        "  output = model.predict(X_test)\n",
        "  end_time = time.time()\n",
        "  # Calculate time taken per frame\n",
        "  time_per_frame = end_time - start_time\n",
        "  num_frames = X_test.shape[0]\n",
        "  time_per_frame = total_time / num_frames\n",
        "  fps = 1 / time_per_frame\n",
        "  print(f\"FPS: {fps:.2f}\")\n",
        "\n",
        "  print(f'IoU Score: {iou_score}')\n",
        "  print(f'Dice Coefficient: {dice_score}')\n",
        "  print(f'Average Precision (AP): {ap}')\n",
        "  print(f'Recall: {recall}')\n",
        "  print(f'Localization Recall Accuracy (LRA) : {lra}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_dt(dt1, dt2):\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  plt.imshow(dt1,cmap='viridis')\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  plt.imshow(dt2,cmap='viridis')\n",
        "\n",
        "idx = 177\n",
        "def plot_frame(idx):\n",
        "  print('RGB image')\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  plt.imshow(X_test[idx,:,:,0:3])\n",
        "\n",
        "  print('Ground truth')\n",
        "  plot_dt(y_test[idx,:,:,0], y_test[idx,:,:,1])\n",
        "  print('Prediction')\n",
        "  plot_dt(y_pred[idx,:,:,0], y_pred[idx,:,:,1])\n",
        "  print('Treshold prediction')\n",
        "  plot_dt(y_pred_thresholded[idx,:,:,0], y_pred_thresholded[idx,:,:,1])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ACH3Z7JOMX-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyPvj80KZugMkjO95zx/m7Dl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}